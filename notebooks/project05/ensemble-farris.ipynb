{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84141911",
   "metadata": {},
   "source": [
    "# **Wine Quality Prediction: Ensemble Model Comparison Project**\n",
    "**Author:** Joanna Farris  \n",
    "**Date:** November 20, 2025  \n",
    "**Objective:** Explore whether ensemble methods (AdaBoost, Random Forest, and a Voting Classifier) can improve classification performance on the Wine dataset compared to the individual base models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345f02b",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "This project explores different machine learning models to predict outcomes from our dataset. I will test Random Forest, Decision Tree, SVM, Neural Network, and a Voting classifier to evaluate their performance. The goal is to identify which approaches work best, understand why, and explore ways to improve predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2faaaf1",
   "metadata": {},
   "source": [
    "#### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58bc3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa8d1d4",
   "metadata": {},
   "source": [
    "#### **Section 1. Load and Inspect the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299a78c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (download from UCI and save in the same folder)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51fdeeb",
   "metadata": {},
   "source": [
    "## **Section 2. Prepare the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942a662",
   "metadata": {},
   "source": [
    "Step 1: Create a categorical label from the numeric target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631613b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd625d",
   "metadata": {},
   "source": [
    "Step 2: Create a numeric label for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652cc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_numeric column\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19d33cb",
   "metadata": {},
   "source": [
    "After these two steps, your dataframe has two new columns: \n",
    "\n",
    "| Column| Type | Meaning |\n",
    "|:---|:---|:---|\n",
    "|quality_label|string|Categorical label: \"low\", \"medium\", \"high\"|\n",
    "|quality_numeric|integer|Numeric label: 0 = low, 1 = medium, 2 = high|\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dda4bd",
   "metadata": {},
   "source": [
    "## **Section 3. Feature Selection and Justification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9edee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features (X)\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])\n",
    "\n",
    "# Define target variable\n",
    "y = df[\"quality_numeric\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74ddd7",
   "metadata": {},
   "source": [
    "✅ Justification:  \n",
    "\n",
    "- **Features (X)**: 11 physicochemical properties of wine → meaningful predictors for wine quality.\n",
    "- **Target (y)**: numeric category of wine quality → makes the classification problem manageable and compatible with sklearn models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed288fb6",
   "metadata": {},
   "source": [
    "## **Section 4. Split the Data into Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf734eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd24ee2",
   "metadata": {},
   "source": [
    "#### **Helper function to train and evaluate models** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336bc542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15699dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a052fcb",
   "metadata": {},
   "source": [
    "#### **Model #1: Random Forest (100 trees)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6ce3eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  15  28]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8875\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Model': 'Random Forest (100)',\n",
       "  'Train Accuracy': 1.0,\n",
       "  'Test Accuracy': 0.8875,\n",
       "  'Train F1': 1.0,\n",
       "  'Test F1': 0.8660560842649911}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train and evaluate using the same helper function\n",
    "evaluate_model(\"Random Forest (100)\", rf_model, X_train, y_train, X_test, y_test, results)\n",
    "\n",
    "# Check updated results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3625c3a",
   "metadata": {},
   "source": [
    "#### **Model #2: Voting (DT + SVM + NN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80f7b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Results\n",
      "Confusion Matrix (Test):\n",
      "[[  1  10   2]\n",
      " [  8 229  27]\n",
      " [  3  10  30]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8125\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8188\n",
      "\n",
      "SVM Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 254  10]\n",
      " [  0  25  18]]\n",
      "Train Accuracy: 0.8569, Test Accuracy: 0.8500\n",
      "Train F1 Score: 0.8204, Test F1 Score: 0.8219\n",
      "\n",
      "Neural Net Results\n",
      "Confusion Matrix (Test):\n",
      "[[  3   9   1]\n",
      " [  6 237  21]\n",
      " [  0  13  30]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8438\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8437\n",
      "\n",
      "Voting (DT + SVM + NN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  3 246  15]\n",
      " [  0  13  30]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8625\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Model': 'Random Forest (100)',\n",
       "  'Train Accuracy': 1.0,\n",
       "  'Test Accuracy': 0.8875,\n",
       "  'Train F1': 1.0,\n",
       "  'Test F1': 0.8660560842649911},\n",
       " {'Model': 'Decision Tree',\n",
       "  'Train Accuracy': 1.0,\n",
       "  'Test Accuracy': 0.8125,\n",
       "  'Train F1': 1.0,\n",
       "  'Test F1': 0.8188438252493979},\n",
       " {'Model': 'SVM',\n",
       "  'Train Accuracy': 0.8569194683346364,\n",
       "  'Test Accuracy': 0.85,\n",
       "  'Train F1': 0.8204335064299121,\n",
       "  'Test F1': 0.8219107812341676},\n",
       " {'Model': 'Neural Net',\n",
       "  'Train Accuracy': 1.0,\n",
       "  'Test Accuracy': 0.84375,\n",
       "  'Train F1': 1.0,\n",
       "  'Test F1': 0.8436535114402555},\n",
       " {'Model': 'Voting (DT + SVM + NN)',\n",
       "  'Train Accuracy': 1.0,\n",
       "  'Test Accuracy': 0.8625,\n",
       "  'Train F1': 1.0,\n",
       "  'Test F1': 0.8488954375848033}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Scale the features once\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 2. Define base models\n",
    "dt_model = DecisionTreeClassifier()\n",
    "svc_model = SVC(probability=True)  # Required for soft voting\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(50,), solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# 3. Create voting ensemble\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('DT', dt_model), ('SVM', svc_model), ('NN', nn_model)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 4. Train and evaluate models using scaled data\n",
    "# Use the same scaled data for all models\n",
    "evaluate_model(\"Decision Tree\", dt_model, X_train_scaled, y_train, X_test_scaled, y_test, results)\n",
    "evaluate_model(\"SVM\", svc_model, X_train_scaled, y_train, X_test_scaled, y_test, results)\n",
    "evaluate_model(\"Neural Net\", nn_model, X_train_scaled, y_train, X_test_scaled, y_test, results)\n",
    "evaluate_model(\"Voting (DT + SVM + NN)\", voting_model, X_train_scaled, y_train, X_test_scaled, y_test, results)\n",
    "\n",
    "# 5. Inspect the results\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c30bd",
   "metadata": {},
   "source": [
    "## **Section 6. Compare Results** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9c2d693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of All Models: Ranked by Test Accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Accuracy Gap</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>F1 Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (100)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.88750</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866056</td>\n",
       "      <td>0.133944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voting (DT + SVM + NN)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.86250</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848895</td>\n",
       "      <td>0.151105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.856919</td>\n",
       "      <td>0.85000</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>0.820434</td>\n",
       "      <td>0.821911</td>\n",
       "      <td>-0.001477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843654</td>\n",
       "      <td>0.156346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818844</td>\n",
       "      <td>0.181156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train Accuracy  Test Accuracy  Accuracy Gap  \\\n",
       "0     Random Forest (100)        1.000000        0.88750      0.112500   \n",
       "4  Voting (DT + SVM + NN)        1.000000        0.86250      0.137500   \n",
       "2                     SVM        0.856919        0.85000      0.006919   \n",
       "3              Neural Net        1.000000        0.84375      0.156250   \n",
       "1           Decision Tree        1.000000        0.81250      0.187500   \n",
       "\n",
       "   Train F1   Test F1    F1 Gap  \n",
       "0  1.000000  0.866056  0.133944  \n",
       "4  1.000000  0.848895  0.151105  \n",
       "2  0.820434  0.821911 -0.001477  \n",
       "3  1.000000  0.843654  0.156346  \n",
       "1  1.000000  0.818844  0.181156  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table of results \n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df[\"Accuracy Gap\"] = results_df[\"Train Accuracy\"] - results_df[\"Test Accuracy\"]\n",
    "results_df[\"F1 Gap\"] = results_df[\"Train F1\"] - results_df[\"Test F1\"]\n",
    "\n",
    "# Reorder and rename columns for readability\n",
    "results_df = results_df[\n",
    "    [\"Model\", \"Train Accuracy\", \"Test Accuracy\", \"Accuracy Gap\", \"Train F1\", \"Test F1\", \"F1 Gap\"]\n",
    "]\n",
    "\n",
    "# Sort by Test Accuracy\n",
    "results_df.sort_values(by=\"Test Accuracy\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"\\nSummary of All Models: Ranked by Test Accuracy\")\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0345e",
   "metadata": {},
   "source": [
    "## **Section 7. Conclusions and Insights**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d5cf3b",
   "metadata": {},
   "source": [
    "Random Forest performed best, with 88.75% test accuracy and an F1 of 0.866. It likely beat a single decision tree because combining 100 trees reduces overfitting while capturing different patterns in the data. The Voting classifier improved on its base models, but nothing topped Random Forest. SVM was stable but slightly underfit, and the neural net overfit a bit. Next steps could be tuning Random Forest and adding some feature engineering to boost performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied-ml-farris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
